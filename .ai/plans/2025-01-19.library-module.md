# Library Module Implementation Plan

**Created:** 2025-01-19
**Status:** Draft (Pending User Approval)
**Type:** New Feature Development
**Reviewed By:** Rust Developer, Database Expert, Schema Architect, Feature Tester

## Executive Summary

This plan covers the complete implementation of the `lib` module for the Composition project - a Rust library for document composition using the DarkMatter DSL. The library provides transclusion, AI-powered summarization/consolidation, smart image processing, and caching via SurrealDB.

---

## Sub-Agent Review Summary

### Critical Issues Identified (Must Address)

1. **Async/Sync Runtime Strategy** - Plan mixes rayon (sync) with tokio (async) without clear integration strategy. Risk of deadlocks.
2. **Missing Core Type Definitions** - DarkMatterNode AST, Frontmatter, Document, and Resource types lack concrete specifications.
3. **SurrealDB Embedded Validation** - Need early spike to validate embedded mode before committing to Phase 1.
4. **Vector Embedding Dimension Mismatch** - fastembed (384 dim) vs OpenAI (1536 dim) incompatibility not addressed.
5. **No Mocking Strategy for AI** - Phase 6 tests marked "may skip in CI" but no unit test mocking approach.

### Major Issues Identified

1. **Document Graph Schema Missing** - SurrealDB schema for dependencies marked "TBD" in docs.
2. **Cache Invalidation Algorithm Unspecified** - Cascade invalidation not detailed.
3. **Memory Limits for Image Processing** - No backpressure mechanism for large batches.
4. **Property Tests Not Integrated** - proptest mentioned but not in phase plans.
5. **Test Infrastructure Absent** - No fixtures, mocks, or golden outputs planned.

### Recommended Resolution

**Runtime Strategy:** Adopt async-first with `tokio` as primary runtime. Use `tokio::task::spawn_blocking` for rayon CPU-bound work. Add `tokio` to Phase 1 dependencies.

**Type Definitions:** Add concrete type specifications to Phase 1.2 (see Appendix A below).

**Database Validation:** Add Phase 0 spike task before Phase 1 begins.

**Embedding Strategy:** Standardize on 1536 dimensions or use separate HNSW indexes per model.

## Functional Requirements

### Core API Functions (from library-features.md)

1. **`init(dir?, frontmatter?)`** - Initialize library with database location and starting frontmatter
2. **`graph(resource)`** - Build dependency graph for a document
3. **`generateWorkplan(resources[])`** - Create optimized parsing plan with concurrency layers
4. **`render(resources[], state?)`** - Orchestrate rendering with concurrency via rayon
5. **`toHTML(glob[])`** - Convert markdown to self-contained HTML

### Supplemental API Functions

1. **`transclude(file|url)`** - Resolve DarkMatter references recursively
2. **`optimizeImage(file|url)`** - Generate smart image variants
3. **`summarize(resource, &frontmatter)`** - AI-powered content summarization
4. **`consolidate(resource[], &frontmatter)`** - AI-powered document consolidation
5. **`topicExtraction(topic, resource[])`** - AI-powered topic extraction

### DarkMatter DSL Features (from darkmatter-dsl.md)

- Transclusion: `::file ./path.md`
- Summarization: `::summarize ./doc.md`
- Consolidation: `::consolidate ./a.md ./b.md`
- Topic extraction: `::topic "topic" ./a.md ./b.md`
- Tables: `::table --with-heading-row` (inline & external)
- Charts: `::bar-chart`, `::line-chart`, etc.
- Popovers: `[text](popover:content)` and `::popover`
- List expansion: `*`, `-`, `+` semantics
- Text replacement via frontmatter
- Smart images: responsive images with srcset
- Frontmatter interpolation: `{{variable}}`
- Disclosure blocks: `::summary`/`::details`
- Block columns: `::columns`/`::break`

### Non-Functional Requirements

- **Performance**: Parallel processing via rayon for images and documents
- **Caching**: SurrealDB with embedded RocksDB for offline persistence
- **Error Handling**: thiserror for typed errors
- **Logging**: tracing with OpenTelemetry support
- **Hashing**: xxhash-rust XXH3-64 for content/resource hashing

---

## Phase 0: Validation Spike (Pre-Implementation)

**Goal:** Validate critical technology choices before committing to implementation.

### Tasks

0.1. **SurrealDB Embedded Mode Validation**
   - Create prototype with embedded RocksDB backend
   - Test concurrent read/write operations
   - Verify graph edge creation and traversal
   - Test database file creation and recovery
   - Benchmark basic CRUD operations

0.2. **Async/Sync Integration Prototype**
   - Prototype tokio + rayon integration
   - Verify `spawn_blocking` works with rayon thread pool
   - Test AI call inside async context
   - Confirm no deadlocks under concurrent load

0.3. **Embedding Dimension Decision**
   - Document chosen embedding dimension (recommend: 1536)
   - Decide: single index vs per-model indexes
   - Create test with fastembed using dimension-matched model

### Success Criteria
- [ ] SurrealDB embedded mode handles 1000 concurrent operations without errors
- [ ] `spawn_blocking` + rayon processes 50 items concurrently without deadlock
- [ ] Embedding strategy documented and validated

### Duration
1-2 days of investigation

---

## Phase 1: Core Infrastructure

**Goal:** Establish foundational types, error handling, database connectivity, and project scaffolding.

### Tasks

1.1. **Project Structure Setup**
   - Create module hierarchy: `lib/src/{types, error, cache, parse, render, ai}`
   - Set up `Cargo.toml` with core dependencies
   - Configure feature flags for optional AI providers
   - **Decide on async vs sync public API** (recommend: async-first)

1.2. **Core Types Definition** (see Appendix A for full specifications)
   - Define `Resource` struct with source, requirement, and cache duration
   - Define `DarkMatterNode` AST enum for all DSL elements
   - Define `Frontmatter` struct with darkmatter reserved properties
   - Define `Document` struct representing parsed documents
   - Define `CompositionApi` handle struct

1.3. **Error Types (thiserror)**
   - `CompositionError` - top-level error enum with variants:
     - `Parse(ParseError)`
     - `Cache(CacheError)`
     - `Render(RenderError)`
     - `AI(AIError)`
   - `ParseError` - markdown/DSL parsing errors with line numbers
   - `CacheError` - database operation errors
   - `RenderError` - rendering pipeline errors
   - `AIError` - LLM operation errors with provider context

1.4. **SurrealDB Integration**
   - Initialize embedded RocksDB database
   - Define schema for document graph (see Appendix B)
   - Define schema for image cache with TTL field
   - Define schema for LLM response cache with composite indexes
   - Implement cache operations (get, upsert, invalidate)
   - **Add composite indexes for query patterns**
   - **Implement cascade invalidation algorithm**

1.5. **Init Function**
   - Implement project scope detection (git vs non-git)
   - Locate/create database file
   - Merge ENV, utility frontmatter, and passed frontmatter
   - Return `CompositionApi` handle with Arc-wrapped DB connection

1.6. **Test Infrastructure Setup**
   - Create `tests/common/mod.rs` with shared utilities
   - Set up mock providers for AI (trait-based)
   - Create fixture directory structure
   - Add proptest dependency for property tests

### Dependencies (Cargo.toml additions)
```toml
# Runtime
tokio = { version = "1", features = ["full"] }

# Database
surrealdb = { version = "2", features = ["kv-rocksdb"] }

# Error handling
thiserror = "2"

# Logging
tracing = "0.1"

# Hashing
xxhash-rust = { version = "0.8", features = ["xxh3"] }

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"
chrono = { version = "0.4", features = ["serde"] }

# Testing
proptest = "1"
```

### Test Scope
- `lib/src/**/*.rs` - unit tests in `#[cfg(test)] mod tests`
- `tests/infrastructure_*.rs` - integration tests for database operations
- **Property tests for cache operations**

### Success Criteria
- [ ] `init()` successfully initializes database (async)
- [ ] Error types compile and propagate correctly with `?` operator
- [ ] Cache operations (CRUD) pass tests including cascade invalidation
- [ ] Project scope detection works for git and non-git directories
- [ ] Test infrastructure (mocks, fixtures) is available for subsequent phases

---

## Phase 2: Markdown Parsing & DSL Recognition

**Goal:** Parse CommonMark/GFM markdown and recognize DarkMatter DSL extensions.

### Tasks

2.1. **pulldown-cmark Integration**
   - Set up parser with GFM extensions enabled (tables, strikethrough, tasklists)
   - Create event stream processing pipeline
   - Implement frontmatter extraction (YAML)

2.2. **DarkMatter DSL Parser**
   - Recognize block directives: `::file`, `::summarize`, `::consolidate`, `::topic`, etc.
   - Recognize inline syntax: `[text](popover:content)`, `{{variable}}`
   - Parse directive options/flags
   - Build DarkMatter AST nodes

2.3. **Frontmatter Processing**
   - Parse YAML frontmatter using markdown-frontmatter crate
   - Merge with utility frontmatter defaults
   - Support frontmatter interpolation in content

2.4. **Resource References**
   - Parse local file references (relative/absolute paths)
   - Parse URL references (HTTP/HTTPS)
   - Parse glob patterns for multi-file operations
   - Handle required (`!`) and optional (`?`) suffixes

### Dependencies (Cargo.toml additions)
```toml
pulldown-cmark = { version = "0.13", features = ["simd"] }
markdown-frontmatter = "0.3"
glob = "0.3"
url = "2"
```

### Test Scope
- `lib/src/parse/**/*.rs` - unit tests
- `tests/parse_*.rs` - integration tests with sample markdown files

### Success Criteria
- [ ] Standard CommonMark/GFM renders correctly
- [ ] All DarkMatter directives are recognized and parsed
- [ ] Frontmatter is extracted and accessible
- [ ] Resource references are parsed with correct semantics

---

## Phase 3: Document Graph & Dependency Resolution

**Goal:** Build and persist document dependency graphs, detect cycles, generate work plans.

### Tasks

3.1. **Graph Building**
   - Walk parsed document for resource references
   - Recursively parse referenced documents
   - Build directed graph of dependencies
   - Store graph in SurrealDB using graph edges

3.2. **Cycle Detection**
   - Implement DAG validation
   - Detect circular dependencies
   - Provide clear error messages with cycle path

3.3. **Work Plan Generation**
   - Identify fresh cached resources (skip)
   - Group non-cached resources into layers
   - Order layers by dependency (leaves first)
   - Optimize for parallel execution

3.4. **Graph Caching**
   - Persist dependency graph to database
   - Detect graph changes on re-parse
   - Invalidate downstream caches on change

### Dependencies (Cargo.toml additions)
```toml
petgraph = "0.6"  # Graph data structure
```

### Test Scope
- `lib/src/graph/**/*.rs` - unit tests
- `tests/graph_*.rs` - integration tests with document hierarchies

### Success Criteria
- [ ] `graph()` returns accurate dependency tree
- [ ] Circular dependencies are detected and reported
- [ ] `generateWorkplan()` produces valid execution layers
- [ ] Graph persists and invalidates correctly

---

## Phase 4: Smart Image Processing

**Goal:** Implement responsive image optimization with caching.

### Tasks

4.1. **Image Source Handling**
   - Load local images
   - Fetch remote images (with HTTP client)
   - Compute resource and content hashes

4.2. **Image Processing Pipeline**
   - Detect transparency
   - Resize to breakpoint widths (Tailwind-based)
   - Generate AVIF, WebP, JPEG/PNG variants
   - Generate blur placeholder

4.3. **Metadata Extraction**
   - Extract EXIF metadata
   - Support metadata stripping options
   - Support metadata-to-alt-text mapping

4.4. **Parallel Processing with Rayon**
   - Configure thread pool
   - Process multiple images in parallel
   - Memory-safe thread count limiting

4.5. **HTML Generation**
   - Generate `<picture>` elements with srcset
   - Implement `sizes` attribute with `auto` support
   - Support layout options (full-width, fixed, percentage)

### Dependencies (Cargo.toml additions)
```toml
image = { version = "0.25", default-features = false, features = ["png", "jpeg", "webp", "avif", "gif"] }
kamadak-exif = "0.5"
rayon = "1.8"
reqwest = { version = "0.12", features = ["blocking"] }
```

### Test Scope
- `lib/src/image/**/*.rs` - unit tests
- `tests/smart_image_*.rs` - integration tests with sample images

### Success Criteria
- [ ] All breakpoint sizes generated correctly
- [ ] Format detection (transparency) works
- [ ] Cache prevents reprocessing unchanged images
- [ ] Parallel processing shows speedup
- [ ] HTML output matches spec

---

## Phase 5: Basic Rendering Pipeline

**Goal:** Implement transclusion and basic rendering without AI features.

### Tasks

5.1. **Transclusion Implementation**
   - Resolve `::file` directives
   - Support local and remote files
   - Recursive resolution of nested transclusions
   - Apply caching semantics (1 day default for HTTP)

5.2. **Content Resolution**
   - Process frontmatter interpolation `{{var}}`
   - Apply text replacements from frontmatter
   - Resolve smart images in content

5.3. **Table Rendering**
   - Parse inline table syntax
   - Parse external CSV files
   - Generate HTML table output

5.4. **Render Orchestration**
   - Implement work plan execution
   - Parallel rendering with rayon
   - Progress reporting via tracing

5.5. **HTML Output**
   - Convert rendered markdown to HTML
   - Inline CSS styles
   - Inline images (base64 or resolved paths)
   - Handle internal links

### Dependencies (Cargo.toml additions)
```toml
csv = "1.3"  # For external table data
base64 = "0.22"  # For inline images
```

### Test Scope
- `lib/src/render/**/*.rs` - unit tests
- `tests/render_*.rs` - integration tests with document hierarchies

### Success Criteria
- [ ] Basic transclusion works recursively
- [ ] Frontmatter interpolation resolves correctly
- [ ] Tables render from inline and external sources
- [ ] `toHTML()` produces valid self-contained HTML

---

## Phase 6: AI Integration (LLM Operations)

**Goal:** Implement AI-powered summarization, consolidation, and topic extraction.

### Tasks

6.1. **Use rig-core Traits Directly** (per Rust Developer review)
   - Use `rig::completion::CompletionModel` trait directly
   - Use `rig::embeddings::EmbeddingModel` trait directly
   - Implement factory function for model string parsing (e.g., "openai/gpt-4o")
   - **Do not create unnecessary abstraction layer**

6.2. **rig-core Provider Setup**
   - OpenAI provider via `rig::providers::openai`
   - Anthropic provider via `rig::providers::anthropic`
   - Ollama provider via `rig::providers::ollama`
   - OpenRouter via OpenAI-compatible API with custom base URL

6.3. **Summarization**
   - Implement `summarize()` function using async runtime
   - Cache results by input hash + model in SurrealDB
   - Support model override via frontmatter
   - Use `tokio::task::spawn_blocking` if needed for sync contexts

6.4. **Consolidation**
   - Implement `consolidate()` function
   - Support multiple input documents
   - Cache results

6.5. **Topic Extraction**
   - Implement `topicExtraction()` function
   - Support structured output extraction via rig's `extractor` feature
   - Cache results

6.6. **Embedding Support**
   - Cloud embeddings via rig-core (1536 dimensions standard)
   - Local embeddings via fastembed with compatible model (e.g., BGE-Large, 1024 dim)
   - **Standardize on 1536 dimensions or use separate HNSW indexes**
   - Store embeddings in SurrealDB with HNSW index

6.7. **Mock Provider for Testing**
   - Implement `MockCompletionModel` for deterministic unit tests
   - Implement `MockEmbeddingModel` with fixed vectors
   - Test double records call count for verification

### Dependencies (Cargo.toml additions)
```toml
rig-core = { version = "0.9", features = ["derive"] }
rig-fastembed = "0.1"
# tokio already added in Phase 1
```

### Test Scope
- `lib/src/ai/**/*.rs` - unit tests with **mock providers** (deterministic)
- `tests/ai_*.rs` - integration tests (require API keys, skipped in CI with `#[ignore]`)
- **Property tests**: cache hit after insert, stale cache detection

### Success Criteria
- [ ] Multiple providers work with rig-core traits
- [ ] LLM responses are cached and retrieved correctly
- [ ] Mock providers enable offline unit testing
- [ ] Summarization produces reasonable output (integration test)
- [ ] Consolidation merges documents coherently
- [ ] Topic extraction finds relevant content

---

## Phase 7: Advanced DSL Features

**Goal:** Implement remaining DarkMatter DSL features.

### Tasks

7.1. **Charting**
   - Bar chart generation
   - Line chart generation
   - Pie/donut chart generation
   - Area chart, bubble chart
   - SVG output for embedding

7.2. **Popovers**
   - Inline popover syntax parsing
   - Block popover rendering
   - HTML/CSS output generation

7.3. **List Expansion**
   - Parse `*`/`-`/`+` semantics
   - Generate collapsible HTML
   - Support frontmatter default

7.4. **Disclosure Blocks**
   - Parse `::summary`/`::details` syntax
   - Generate `<details>` HTML elements

7.5. **Block Columns**
   - Parse `::columns`/`::break` syntax
   - Generate responsive CSS grid/flex layout
   - Support breakpoint-based column counts

### Dependencies (Cargo.toml additions)
```toml
# TBD - evaluate charting libraries (possibly custom SVG generation)
```

### Test Scope
- `lib/src/dsl/**/*.rs` - unit tests for each feature
- `tests/dsl_*.rs` - integration tests

### Success Criteria
- [ ] All chart types render to SVG
- [ ] Popovers generate valid HTML/CSS
- [ ] List expansion works with defaults
- [ ] Disclosure blocks render correctly
- [ ] Columns are responsive

---

## Phase 8: Integration & Polish

**Goal:** End-to-end integration, performance optimization, and documentation.

### Tasks

8.1. **Full Pipeline Integration**
   - Test complete workflows with real documents
   - Verify caching across all stages
   - Test error propagation and recovery

8.2. **Performance Optimization**
   - Profile hot paths
   - Optimize memory allocation patterns
   - Benchmark with criterion

8.3. **Public API Stabilization**
   - Review and document public API
   - Ensure proper visibility (pub/pub(crate))
   - Add comprehensive doc comments with examples

8.4. **Tracing & Observability**
   - Add spans for key operations
   - Instrument with `#[instrument]`
   - Support JSON output for production

8.5. **Documentation**
   - Module-level documentation
   - Public API documentation with examples
   - Usage guide

### Dependencies (Cargo.toml additions)
```toml
criterion = { version = "0.5", features = ["html_reports"] }
tracing-subscriber = { version = "0.3", features = ["json", "env-filter"] }
```

### Test Scope
- All existing tests
- `benches/*.rs` - criterion benchmarks
- `tests/e2e_*.rs` - end-to-end workflow tests

### Success Criteria
- [ ] Complete document composition workflow passes
- [ ] Benchmarks establish baseline performance
- [ ] All public APIs are documented
- [ ] Tracing provides useful observability

---

## Implementation Order & Dependencies

```
Phase 1 (Core Infrastructure)
    │
    ▼
Phase 2 (Parsing) ◄──────────────┐
    │                            │
    ▼                            │
Phase 3 (Graph)                  │
    │                            │
    ├──────────┬─────────────────┤
    ▼          ▼                 │
Phase 4    Phase 5               │
(Images)   (Rendering)           │
    │          │                 │
    └────┬─────┘                 │
         ▼                       │
      Phase 6 (AI) ──────────────┘
         │
         ▼
      Phase 7 (Advanced DSL)
         │
         ▼
      Phase 8 (Integration)
```

- Phase 1 is prerequisite for all others
- Phase 2 is prerequisite for Phases 3-7
- Phase 4 and 5 can proceed in parallel after Phase 3
- Phase 6 depends on parsing and rendering foundations
- Phase 7 can proceed after Phase 5
- Phase 8 integrates everything

---

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| SurrealDB embedded mode limitations | Medium | Medium | Test early; have SQLite fallback plan |
| AI provider API changes | Low | Medium | Abstract behind traits; pin versions |
| Image processing memory issues | Medium | High | Cap thread pool; test with large images |
| Complex DSL edge cases | High | Low | Comprehensive test suite; fuzzing |
| Chart rendering complexity | Medium | Medium | Start with simple SVG; evaluate crates |

---

## Estimated Complexity

| Phase | Lines of Code (est.) | Complexity |
|-------|---------------------|------------|
| Phase 1 | ~1,500 | Medium |
| Phase 2 | ~2,000 | High |
| Phase 3 | ~1,000 | Medium |
| Phase 4 | ~1,500 | Medium |
| Phase 5 | ~2,000 | High |
| Phase 6 | ~1,500 | Medium |
| Phase 7 | ~2,500 | High |
| Phase 8 | ~500 | Low |

**Total:** ~12,500 lines of Rust code (estimated)

---

## Notes for Review Agents

### For Rust Developer Agent
- Review Rust idioms and patterns in each phase
- Validate error handling strategy
- Assess async vs sync decisions
- Review trait design for extensibility

### For Database Expert Agent
- Validate SurrealDB schema design
- Review caching strategy for efficiency
- Assess graph storage approach
- Recommend indexing strategy

### For Schema Architect Agent
- Review type definitions for completeness
- Assess API ergonomics
- Validate data flow through system
- Review serialization approach

### For Feature Tester Agent (Rust)
- Plan test strategy for each phase
- Identify edge cases and property tests
- Recommend integration test structure
- Assess testability of design

---

## Appendix A: Core Type Specifications

Per Schema Architect review, these concrete types should be implemented in Phase 1.2.

### Resource Types

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Resource {
    pub source: ResourceSource,
    pub requirement: ResourceRequirement,
    pub cache_duration: Option<Duration>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ResourceSource {
    Local(PathBuf),
    Remote(Url),
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, Default)]
pub enum ResourceRequirement {
    Required,   // `!` suffix - error if missing
    Optional,   // `?` suffix - silent if missing
    #[default]
    Default,    // no suffix - warning if missing
}
```

### DarkMatter AST Types

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", content = "data")]
pub enum DarkMatterNode {
    // Transclusion
    File { resource: Resource, range: Option<LineRange> },

    // AI operations
    Summarize { resource: Resource },
    Consolidate { resources: Vec<Resource> },
    Topic { topic: String, resources: Vec<Resource>, review: bool },

    // Tables & Charts
    Table { source: TableSource, has_heading: bool },
    BarChart { data: ChartData },
    LineChart { data: ChartData },
    PieChart { data: ChartData },
    AreaChart { data: ChartData },
    BubbleChart { data: ChartData },

    // Layout
    Popover { trigger: Box<DarkMatterNode>, content: Vec<DarkMatterNode> },
    Columns { breakpoints: HashMap<Breakpoint, u32>, sections: Vec<Vec<DarkMatterNode>> },
    Disclosure { summary: Vec<DarkMatterNode>, details: Vec<DarkMatterNode> },

    // Text/content
    Text(String),
    Interpolation { variable: String },
    Markdown(MarkdownContent),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum TableSource {
    Inline(Vec<Vec<String>>),
    External(Resource),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ChartData {
    Inline(Vec<DataPoint>),
    External(Resource),
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub enum Breakpoint { Xs, Sm, Md, Lg, Xl, Xxl }
```

### Frontmatter Types

```rust
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct Frontmatter {
    // User-defined key-values
    #[serde(flatten)]
    pub custom: HashMap<String, serde_json::Value>,

    // Reserved darkmatter properties
    #[serde(skip_serializing_if = "Option::is_none")]
    pub list_expansion: Option<ListExpansion>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub replace: Option<HashMap<String, String>>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub summarize_model: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub consolidate_model: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub breakpoints: Option<Breakpoints>,
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, Default)]
pub enum ListExpansion {
    Expanded,
    Collapsed,
    #[default]
    None,
}
```

### Document & API Types

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Document {
    pub resource: Resource,
    pub frontmatter: Frontmatter,
    pub content: Vec<DarkMatterNode>,
    pub dependencies: Vec<Resource>,
    pub parsed_at: DateTime<Utc>,
}

pub struct CompositionApi {
    cache: Arc<ImageCache>,
    db: Arc<Surreal<Db>>,
    frontmatter: Frontmatter,
    config: CompositionConfig,
}

impl CompositionApi {
    pub async fn graph(&self, resource: Resource) -> Result<DependencyGraph>;
    pub async fn generate_workplan(&self, resources: Vec<Resource>) -> Result<WorkPlan>;
    pub async fn render(&self, resources: Vec<Resource>, state: Option<Frontmatter>) -> Result<Vec<Document>>;
    pub async fn to_html(&self, patterns: Vec<String>) -> Result<Vec<HtmlOutput>>;

    // Supplemental API
    pub async fn transclude(&self, resource: Resource) -> Result<Document>;
    pub async fn optimize_image(&self, source: ImageSource) -> Result<SmartImageOutput>;
    pub async fn summarize(&self, resource: Resource) -> Result<String>;
    pub async fn consolidate(&self, resources: Vec<Resource>) -> Result<String>;
    pub async fn topic_extraction(&self, topic: &str, resources: Vec<Resource>) -> Result<String>;
}
```

### Graph Types

```rust
#[derive(Debug, Clone)]
pub struct DependencyGraph {
    pub root: Resource,
    pub nodes: HashMap<ResourceHash, GraphNode>,
    pub edges: Vec<(ResourceHash, ResourceHash)>,
}

#[derive(Debug, Clone)]
pub struct WorkPlan {
    pub layers: Vec<WorkLayer>,
    pub total_tasks: usize,
}

#[derive(Debug, Clone)]
pub struct WorkLayer {
    pub resources: Vec<Resource>,
    pub parallelizable: bool,
}

pub type ResourceHash = u64;
```

---

## Appendix B: SurrealDB Schema Definitions

Per Database Expert review, define these schemas before Phase 1 implementation.

### Document Graph Schema

```sql
-- Document node
DEFINE TABLE document SCHEMAFULL;
DEFINE FIELD resource_hash ON document TYPE string;
DEFINE FIELD content_hash ON document TYPE string;
DEFINE FIELD file_path ON document TYPE option<string>;
DEFINE FIELD url ON document TYPE option<string>;
DEFINE FIELD last_validated ON document TYPE datetime;
DEFINE INDEX idx_resource_hash ON document FIELDS resource_hash UNIQUE;

-- Dependency edge (using SurrealDB graph relations)
DEFINE TABLE depends_on SCHEMAFULL TYPE RELATION IN document OUT document;
DEFINE FIELD reference_type ON depends_on TYPE string; -- "transclusion", "image", "summarize", etc.
DEFINE FIELD required ON depends_on TYPE bool DEFAULT false; -- for ! suffix
```

### Image Cache Schema

```sql
DEFINE TABLE image_cache SCHEMAFULL;
DEFINE FIELD resource_hash ON image_cache TYPE string;
DEFINE FIELD content_hash ON image_cache TYPE string;
DEFINE FIELD created_at ON image_cache TYPE datetime DEFAULT time::now();
DEFINE FIELD expires_at ON image_cache TYPE option<datetime>; -- for remote images
DEFINE FIELD source_type ON image_cache TYPE string; -- "local" or "remote"
DEFINE FIELD source ON image_cache TYPE string;
DEFINE FIELD has_transparency ON image_cache TYPE bool;
DEFINE FIELD original_width ON image_cache TYPE int;
DEFINE FIELD original_height ON image_cache TYPE int;

-- Indexes
DEFINE INDEX idx_resource_hash ON image_cache FIELDS resource_hash UNIQUE;
DEFINE INDEX idx_image_lookup ON image_cache FIELDS resource_hash, content_hash;
```

### LLM Cache Schema

```sql
DEFINE TABLE llm_cache SCHEMAFULL;
DEFINE FIELD operation ON llm_cache TYPE string;  -- "summarize", "consolidate", "topic"
DEFINE FIELD input_hash ON llm_cache TYPE string;
DEFINE FIELD model ON llm_cache TYPE string;
DEFINE FIELD response ON llm_cache TYPE string;
DEFINE FIELD created_at ON llm_cache TYPE datetime DEFAULT time::now();
DEFINE FIELD expires_at ON llm_cache TYPE datetime;
DEFINE FIELD tokens_used ON llm_cache TYPE option<int>;

-- Composite index for fast lookups
DEFINE INDEX idx_llm_lookup ON llm_cache FIELDS operation, input_hash, model;
DEFINE INDEX idx_expires ON llm_cache FIELDS expires_at;
```

### Vector Embedding Schema

```sql
DEFINE TABLE embedding SCHEMAFULL;
DEFINE FIELD resource_hash ON embedding TYPE string;
DEFINE FIELD content_hash ON embedding TYPE string;
DEFINE FIELD model ON embedding TYPE string;
DEFINE FIELD vector ON embedding TYPE array<float>;
DEFINE FIELD created_at ON embedding TYPE datetime DEFAULT time::now();

-- HNSW vector index (1536 dimensions for OpenAI compatibility)
DEFINE INDEX idx_embedding_vector ON embedding
    FIELDS vector HNSW DIMENSION 1536 DISTANCE COSINE;
DEFINE INDEX idx_embedding_resource ON embedding FIELDS resource_hash UNIQUE;
```

---

## Appendix C: Test Infrastructure

Per Feature Tester review, establish this infrastructure in Phase 1.6.

### Directory Structure

```
tests/
├── common/
│   ├── mod.rs           # Shared utilities
│   ├── fixtures.rs      # Test fixture creation
│   ├── mocks.rs         # Mock providers
│   └── assertions.rs    # Custom assertions
├── fixtures/
│   ├── documents/       # Sample markdown/DarkMatter files
│   ├── images/          # Test images (various sizes/formats)
│   └── expected/        # Golden output files
└── *.rs                 # Integration tests
```

### Key Property Tests

```rust
// Graph properties
proptest! {
    #[test]
    fn acyclic_graph_always_generates_workplan(graph in arbitrary_dag()) {
        let plan = generate_workplan(graph)?;
        assert!(plan.layers.iter().all(|l| !l.is_empty()));
    }

    #[test]
    fn workplan_respects_dependencies(graph in arbitrary_dag()) {
        let plan = generate_workplan(graph)?;
        for (idx, layer) in plan.layers.iter().enumerate() {
            for node in layer {
                for dep in node.dependencies() {
                    assert!(processed_before(dep, idx, &plan));
                }
            }
        }
    }
}

// Image processing properties
proptest! {
    #[test]
    fn never_upsamples_images(width in 100u32..5000, height in 100u32..5000) {
        let img = generate_test_image(width, height);
        let variants = generate_variants(&img, ...);
        assert!(variants.iter().all(|v| v.width <= width));
    }
}

// Cache properties
proptest! {
    #[test]
    fn cache_hit_after_insert(hash in "[a-f0-9]{16}", content in "[a-f0-9]{16}") {
        cache.upsert(entry).await?;
        let result = cache.get(&hash, &content).await?;
        assert!(result.is_some());
    }
}
```

---

## Revision History

| Date | Version | Changes |
|------|---------|---------|
| 2025-01-19 | 0.1 | Initial draft |
| 2025-01-19 | 0.2 | Added Phase 0 spike, consolidated sub-agent feedback, added appendices with type/schema specifications |
