# Cache Strategy

## **IMPORTANT**

Currently, the dependency graph is built in-memory using Rust's HashMap and topological sorting. The
database is only used for:

- Persisting nodes and edges
- Loading single nodes
- Simple cascade invalidation



This document details the comprehensive caching strategy implemented in the Composition library module, including dependency graph caching, asset processing caches, and AI operation caches.

## Overview

The caching system uses **SurrealDB** as its backing store, providing a unified, persistent cache across all system components. The cache strategy follows these principles:

1. **Content-addressed caching**: Uses both resource hashes (location) and content hashes (actual content) to determine cache validity
2. **Differential expiration**: Different cache types have different expiration policies based on their volatility
3. **Graph-aware invalidation**: Document changes cascade to dependent documents
4. **Optimistic cache hits**: Check cache before expensive operations (processing, network, LLM calls)

## Database Location

The cache database location is determined by the project scope:

- **Git repositories**: `{repo_root}/.composition.db`
- **Non-git directories**: `$HOME/.composition.db`

This ensures isolated caches per project while providing a global fallback for ad-hoc usage.

## Cache Types

### 1. Dependency Graph Cache

**Purpose**: Store document dependency graphs to avoid re-parsing and re-building graphs for unchanged documents.

**Schema** (`lib/src/cache/schema.rs:8-22`):

```sql
DEFINE TABLE document SCHEMAFULL;
DEFINE FIELD resource_hash ON document TYPE string;      -- xxh3_64 hash of resource location
DEFINE FIELD content_hash ON document TYPE string;       -- xxh3_64 hash of file content
DEFINE FIELD file_path ON document TYPE option<string>;  -- For local files
DEFINE FIELD url ON document TYPE option<string>;        -- For remote resources
DEFINE FIELD last_validated ON document TYPE datetime;

DEFINE TABLE depends_on SCHEMAFULL;
DEFINE FIELD in ON depends_on TYPE record<document>;     -- Source document
DEFINE FIELD out ON depends_on TYPE record<document>;    -- Target document
DEFINE FIELD reference_type ON depends_on TYPE string;   -- e.g., "transclusion"
DEFINE FIELD required ON depends_on TYPE bool;           -- Required (!) vs optional (?)
```

**Implementation** (`lib/src/graph/cache.rs`):

- `persist_graph()`: Stores graph nodes as document entries and edges as `depends_on` relations
- `load_graph()`: Reconstructs dependency graph from database
    - **Current limitation**: Only loads root node (line 99-101)
    - **Future enhancement**: Recursive graph traversal for full reconstruction

**Invalidation Strategy**:

- Cascade invalidation when a document changes (`lib/src/cache/operations.rs:320-369`)
- Recursively invalidates all documents that depend on the changed document
- Uses graph traversal query to find transitive dependents

**Hash Computation** (`lib/src/graph/utils.rs`):

- Resource hash: `xxh3_64` of canonical resource path/URL
- Content hash: `xxh3_64` of actual file content

**Example**:

```rust
let graph = build_graph(resource, &db, &frontmatter).await?;
persist_graph(&db, &graph).await?;

// Later, check if cached
if let Some(cached_graph) = load_graph(&db, resource).await? {
    // Use cached graph (if content hashes match)
} else {
    // Rebuild graph
}
```

### 2. Image Processing Cache

**Purpose**: Cache expensive image processing operations (resizing, format conversion, blur placeholders).

**Schema** (`lib/src/cache/schema.rs:24-36`):

```sql
DEFINE TABLE image_cache SCHEMAFULL;
DEFINE FIELD resource_hash ON image_cache TYPE string;
DEFINE FIELD content_hash ON image_cache TYPE string;
DEFINE FIELD created_at ON image_cache TYPE datetime;
DEFINE FIELD expires_at ON image_cache TYPE option<datetime>;  -- Remote images: 1 day
DEFINE FIELD source_type ON image_cache TYPE string;           -- "local" | "remote"
DEFINE FIELD source ON image_cache TYPE string;
DEFINE FIELD has_transparency ON image_cache TYPE bool;
DEFINE FIELD original_width ON image_cache TYPE int;
DEFINE FIELD original_height ON image_cache TYPE int;
```

**Expiration Policy** (`lib/src/image/cache.rs:71-75`):

- **Local images**: No expiration (`expires_at = None`)
- **Remote images**: 1 day (86400 seconds) from creation

**Implementation** (`lib/src/image/cache.rs:20-93`):

```rust
pub async fn get_or_process_image(
    source: &ImageSource,
    options: ImageOptions,
    html_options: HtmlOptions,
    db: &Surreal<Db>,
) -> Result<SmartImageOutput>
```

**Workflow**:

1. Compute `resource_hash` from source URL/path
2. Load image and compute `content_hash` from bytes
3. Check cache using `CacheOperations::get_image()`
4. On cache miss: Process image (generate responsive variants, blur placeholder)
5. Store result in cache with appropriate expiration
6. Return `SmartImageOutput`

**Known Limitation** (line 43-46):

```rust
// Cache hit - we would reconstruct the output from cache
// For now, process anyway (cache reconstruction would be implemented in production)
// TODO: Reconstruct SmartImageOutput from cache
```

Currently, even on cache hits, images are reprocessed. Full reconstruction from cached metadata is not yet implemented.

**Cached Data**:

- Metadata (dimensions, transparency detection)
- **Not yet cached**: Processed image variants, blur placeholder base64

### 3. Audio Metadata Cache

**Purpose**: Cache audio file metadata extraction to avoid re-reading media files.

**Schema** (`lib/src/cache/schema.rs:61-74`):

```sql
DEFINE TABLE audio_cache SCHEMAFULL;
DEFINE FIELD resource_hash ON audio_cache TYPE string;
DEFINE FIELD content_hash ON audio_cache TYPE string;
DEFINE FIELD created_at ON audio_cache TYPE datetime;
DEFINE FIELD source_type ON audio_cache TYPE string;    -- "local" | "remote"
DEFINE FIELD source ON audio_cache TYPE string;
DEFINE FIELD format ON audio_cache TYPE string;         -- "mp3" | "wav"
DEFINE FIELD duration_secs ON audio_cache TYPE option<float>;
DEFINE FIELD bitrate ON audio_cache TYPE option<int>;
DEFINE FIELD sample_rate ON audio_cache TYPE option<int>;
DEFINE FIELD channels ON audio_cache TYPE option<int>;
```

**Expiration Policy**:

- **No expiration** for either local or remote audio files
- Upsert behavior: Deletes existing entry with same `resource_hash` before inserting

**Implementation** (`lib/src/audio/cache.rs`):

```rust
pub struct AudioCache {
    db: Surreal<Db>,
}

impl AudioCache {
    pub async fn get(&self, resource_hash: &str, content_hash: &str) -> Result<Option<AudioCacheEntry>>
    pub async fn upsert(&self, new_entry: NewAudioCacheEntry) -> Result<AudioCacheEntry>
    pub async fn clear(&self) -> Result<()>
}
```

**Cache Hit Conditions**:

- `resource_hash` matches (same file path/URL)
- `content_hash` matches (file content unchanged)

### 4. LLM Response Cache

**Purpose**: Cache expensive LLM operations (summarization, consolidation, topic extraction) to avoid redundant API calls.

**Schema** (`lib/src/cache/schema.rs:38-48`):

```sql
DEFINE TABLE llm_cache SCHEMAFULL;
DEFINE FIELD operation ON llm_cache TYPE string;        -- "summarize" | "consolidate" | "topic"
DEFINE FIELD input_hash ON llm_cache TYPE string;       -- xxh3_64 of input text
DEFINE FIELD model ON llm_cache TYPE string;            -- Model identifier
DEFINE FIELD response ON llm_cache TYPE string;         -- Cached LLM response
DEFINE FIELD created_at ON llm_cache TYPE datetime;
DEFINE FIELD expires_at ON llm_cache TYPE datetime;     -- Time-based expiration
DEFINE FIELD tokens_used ON llm_cache TYPE option<int>; -- For cost tracking
```

**Expiration Policy** (`lib/src/ai/summarize.rs:12`):

- Default: **30 days** from creation
- Expired entries are filtered on retrieval (line 286-287 in operations.rs)
- Can be cleaned explicitly with `clean_expired_llm_cache()`

**Implementation** (`lib/src/ai/summarize.rs`):

```rust
pub async fn summarize(
    db: Arc<Surreal<Db>>,
    model: Arc<dyn CompletionModel>,
    text: &str,
    max_tokens: Option<u32>,
) -> Result<String>
```

**Workflow**:

1. Compute `input_hash = xxh3_64(text)`
2. Check cache: `get_llm("summarize", &input_hash, model_name)`
3. On cache hit: Return cached response immediately
4. On cache miss:
   - Call LLM API
   - Store response with 30-day expiration
   - Return response

**Cache Key**: Composite of `(operation, input_hash, model)`

- Same text with different models = different cache entries
- Same text with different operations = different cache entries

**Example from tests** (`lib/src/ai/summarize.rs:178-198`):

```rust
// First call - hits model
let summary1 = summarize(db.clone(), model.clone(), text, None).await?;
assert_eq!(model.call_count(), 1);

// Second call - hits cache
let summary2 = summarize(db, model.clone(), text, None).await?;
assert_eq!(model.call_count(), 1); // Call count unchanged
```

### 5. Vector Embedding Cache

**Purpose**: Cache vector embeddings for semantic search and similarity operations.

**Schema** (`lib/src/cache/schema.rs:50-59`):

```sql
DEFINE TABLE embedding SCHEMAFULL;
DEFINE FIELD resource_hash ON embedding TYPE string;
DEFINE FIELD content_hash ON embedding TYPE string;
DEFINE FIELD model ON embedding TYPE string;
DEFINE FIELD vector ON embedding TYPE array<float>;
DEFINE FIELD created_at ON embedding TYPE datetime;

-- Note: HNSW vector index requires SurrealDB 2.x
-- DEFINE INDEX idx_embedding_vector ON embedding FIELDS vector HNSW DIMENSION 1536 DISTANCE COSINE;
```

**Expiration Policy**:

- **No expiration** (embeddings are deterministic for given content + model)
- Invalidated when content changes (content_hash mismatch)

**Implementation** (`lib/src/ai/embedding.rs`):

```rust
pub async fn generate_embedding(
    db: Arc<Surreal<Db>>,
    model: Arc<dyn EmbeddingModel>,
    resource_hash: &str,
    text: &str,
) -> Result<Vec<f32>>

pub async fn find_similar(
    db: Arc<Surreal<Db>>,
    query_vector: &[f32],
    limit: usize,
    model: Option<&str>,
) -> Result<Vec<(EmbeddingEntry, f32)>>
```

**Workflow**:

1. Compute `content_hash = xxh3_64(text)`
2. Check cache: `get_embedding(resource_hash, content_hash, model)`
3. On cache hit: Return cached vector
4. On cache miss:
   - Call embedding model
   - Validate dimensions match `model.dimensions()`
   - Store embedding
   - Return vector

**Similarity Search** (line 161-209):

- Uses `vector::similarity::cosine()` for cosine similarity
- Supports model filtering (only search within same model's embeddings)
- Returns top-k results with similarity scores

**Future Enhancement**: HNSW index for efficient approximate nearest neighbor search (requires SurrealDB 2.x).

## Cache Operations API

The `CacheOperations` struct (`lib/src/cache/operations.rs`) provides a unified interface to all cache types:

```rust
pub struct CacheOperations {
    db: Surreal<Db>,
}

impl CacheOperations {
    // Document cache
    pub async fn get_document(&self, resource_hash: &str) -> Result<Option<DocumentCacheEntry>>;
    pub async fn upsert_document(&self, entry: DocumentCacheEntry) -> Result<()>;
    pub async fn invalidate_document_cascade(&self, resource_hash: &str) -> Result<Vec<String>>;

    // Image cache
    pub async fn get_image(&self, resource_hash: &str) -> Result<Option<ImageCacheEntry>>;
    pub async fn upsert_image(&self, entry: ImageCacheEntry) -> Result<()>;
    pub async fn invalidate_image(&self, resource_hash: &str) -> Result<()>;

    // LLM cache
    pub async fn get_llm(&self, operation: &str, input_hash: &str, model: &str) -> Result<Option<LlmCacheEntry>>;
    pub async fn upsert_llm(&self, entry: LlmCacheEntry) -> Result<()>;
    pub async fn clean_expired_llm_cache(&self) -> Result<usize>;
}
```

## Hash Functions

All caches use **xxHash (xxh3_64)** for content hashing:

```rust
use xxhash_rust::xxh3::xxh3_64;

// Resource hash (location-based)
let resource_hash = format!("{:016x}", xxh3_64(path.as_bytes()));

// Content hash (content-based)
let content_hash = format!("{:016x}", xxh3_64(file_bytes));
```

**Why xxHash?**

- Non-cryptographic but extremely fast
- Excellent distribution properties
- 64-bit output (compact hash keys)

## Workplan Generation and Caching

The dependency graph enables efficient work planning through topological sorting (`lib/src/graph/workplan.rs`).

**Algorithm**: Kahn's algorithm for topological sort

1. Detect cycles (error if found)
2. Build in-degree map for all nodes
3. Process nodes in layers based on dependencies
4. Each layer contains resources that can be processed in parallel

**Output**: `WorkPlan` with layers

```rust
pub struct WorkPlan {
    pub layers: Vec<WorkLayer>,
    pub total_tasks: usize,
}

pub struct WorkLayer {
    pub resources: Vec<Resource>,
    pub parallelizable: bool,  // All layers are parallelizable
}
```

**Example**: Diamond dependency `A -> B -> D, A -> C -> D`

- Layer 0: `[D]` (the leaf)
- Layer 1: `[B, C]` (parallel processing)
- Layer 2: `[A]` (the root)

**Cache Integration**:

- Load cached graphs to skip re-parsing
- Filter out unchanged resources (content hash matches)
- Only process invalidated subgraphs

## Invalidation Strategies

### Content-Based Invalidation

All caches use dual-hash validation:

1. **Resource hash** identifies the cache entry
2. **Content hash** validates freshness

When content changes:

- Content hash mismatches ’ cache miss
- Old entry remains in cache (garbage collection TBD)

### Time-Based Expiration

Applied to volatile resources:

| Resource Type | Expiration Policy | Rationale |
|--------------|-------------------|-----------|
| Local markdown | None | User controls changes |
| Remote HTTP | 1 day | Content may update upstream |
| LLM responses | 30 days | Balance freshness vs. cost |
| Embeddings | None | Deterministic for content |
| Images (local) | None | User controls source |
| Images (remote) | 1 day | Match HTTP cache policy |
| Audio | None | Large files, infrequent updates |

### Cascade Invalidation

Document changes trigger cascade invalidation (`lib/src/cache/operations.rs:318-369`):

```rust
pub async fn invalidate_document_cascade(&self, resource_hash: &str) -> Result<Vec<String>> {
    // 1. Find all dependents via graph traversal
    SELECT resource_hash FROM (
        SELECT ->depends_on->document AS dependents
        FROM document
        WHERE resource_hash = $hash
    ).dependents.*

    // 2. Delete the document
    DELETE FROM document WHERE resource_hash = $hash

    // 3. Delete all dependents
    for dep_hash in &invalidated_hashes {
        DELETE FROM document WHERE resource_hash = $dep_hash
    }
}
```

**Why cascade?**

- A document change may affect its rendered output
- Any document transcluding the changed document must be re-rendered
- Ensures consistency across the entire dependency graph

## Cache Limitations and Future Work

### Current Limitations

1. **Graph Loading** (`lib/src/graph/cache.rs:99-101`):
   - Only loads root node
   - Full graph traversal not implemented
   - Workaround: Rebuild graph from scratch

2. **Image Cache Reconstruction** (`lib/src/image/cache.rs:43-46`):
   - Cache hit still reprocesses images
   - Need to store processed variants and blur placeholder
   - Current cache only stores metadata

3. **No Garbage Collection**:
   - Stale cache entries accumulate
   - No automatic cleanup of unused entries
   - Expired LLM cache entries must be manually cleaned

4. **No Cache Size Limits**:
   - Database can grow unbounded
   - No LRU eviction
   - No disk space monitoring

5. **Vector Index** (`lib/src/cache/schema.rs:57-58`):
   - HNSW index commented out (requires SurrealDB 2.x)
   - Similarity search uses linear scan
   - Performance degrades with large embedding sets

### Planned Enhancements

**Phase 3** (Current Implementation):

-  Document cache with dependency graph
-  Image cache with basic metadata
-  LLM cache with expiration
-   Graph loading (partial implementation)

**Phase 4** (Audio/Video):

-  Audio metadata cache
- = Video processing cache (not yet implemented)

**Phase 6** (AI Features):

-  Vector embedding cache
-   HNSW index (awaiting SurrealDB 2.x)

**Future Work**:

1. **Full graph reconstruction**: Recursive traversal for loading complete dependency graphs
2. **Image variant storage**: Persist processed image bytes in cache
3. **Garbage collection**: Periodic cleanup of stale entries
4. **Cache statistics**: Hit rate tracking, size monitoring
5. **Incremental invalidation**: Only invalidate affected portions of rendered output
6. **Cache warming**: Pre-populate cache for common operations
7. **Remote cache**: Shared cache across team members
8. **Cache compression**: Reduce storage size for large entries

## Testing Strategy

All cache modules include comprehensive unit tests:

- **Cache hits/misses**: Verify correct cache lookup behavior
- **Expiration**: Ensure time-based expiration works correctly
- **Upsert**: Test update-or-insert semantics
- **Cascade invalidation**: Verify dependency graph invalidation
- **Content hash validation**: Ensure content changes trigger cache misses
- **Concurrent access**: Test parallel cache operations (via rayon integration)

Example test coverage:

- `lib/src/graph/cache.rs`: Graph persist/load tests (lines 126-182)
- `lib/src/image/cache.rs`: Image processing cache test (lines 108-140)
- `lib/src/audio/cache.rs`: Comprehensive cache operations (lines 343-528)
- `lib/src/ai/summarize.rs`: LLM cache hit behavior (lines 178-219)

## Performance Characteristics

### Cache Hit Benefits

| Operation | Without Cache | With Cache Hit | Speedup |
|-----------|--------------|----------------|---------|
| Markdown parse | 1-10ms | <1ms | 10-100x |
| Image processing | 50-500ms | <1ms | 50-500x |
| LLM summarize | 2-10s | <1ms | 2000-10000x |
| Embedding generation | 100-500ms | <1ms | 100-500x |
| Audio metadata | 10-100ms | <1ms | 10-100x |

### Storage Overhead

Typical cache entry sizes:

- Document: ~200 bytes (hash + metadata)
- Image: ~150 bytes (metadata only)
- Audio: ~120 bytes
- LLM response: 100-5000 bytes (varies with response length)
- Embedding: ~6KB (1536 dimensions × 4 bytes)

For a project with:

- 100 documents
- 50 images
- 10 audio files
- 20 LLM calls
- 50 embeddings

Total cache size: ~350KB (excluding LLM responses)

### Database Performance

SurrealDB provides:

- Embedded mode (no network overhead)
- Indexed lookups (O(log n) for hash-based queries)
- Graph traversal queries for dependency analysis
- ACID transactions for consistency

## Conclusion

The caching strategy balances performance, correctness, and storage efficiency through:

1. **Multi-level caching**: Different strategies for different resource types
2. **Content-addressed storage**: Automatic invalidation via content hashing
3. **Graph-aware invalidation**: Ensures consistency across dependencies
4. **Differential expiration**: Tailored policies per resource volatility
5. **Unified database**: Single SurrealDB instance for all cache types

The system is production-ready for core functionality with clear paths for enhancement as described in the Future Work section.
